version: 2.1

environment:
  AWS_REGION: eu-west-2

parameters:
  GHA_Actor:
    type: string
    default: ""
  GHA_Action:
    type: string
    default: ""
  GHA_Event:
    type: string
    default: ""
  GHA_Meta:
    type: string
    default: ""

orbs:
  aws-cli: circleci/aws-cli@5.4.1

jobs:
  task-containerisation:
    parameters:
      aws_account_id:
        type: env_var_name
      access_key:
        type: env_var_name
      secret_key:
        type: env_var_name
    docker:
      - image: docker:latest
    steps:
      - checkout
      - setup_remote_docker:
          docker_layer_caching: true
      - aws-cli/setup:
          region: $AWS_REGION
      - run:
          name: Build Docker Images
          command: |
            export AWS_ACCESS_KEY_ID=${<< parameters.access_key >>}
            export AWS_SECRET_ACCESS_KEY=${<< parameters.secret_key >>}
            # Authenticate Docker to ECR
            aws ecr get-login-password --region eu-west-2 | docker login -u AWS --password-stdin ${<< parameters.aws_account_id >>}.dkr.ecr.eu-west-2.amazonaws.com
            echo "Rebuilding lambdas and pushing to ECR."
            export AWS_ACCOUNT_ID=${<< parameters.aws_account_id >>}
            # This transformation should match the workspace_prefix set in terraform/pipeline/main.tf locals block
            export SANITISED_CIRCLE_BRANCH=$(echo ${CIRCLE_BRANCH:0:30} | tr -c '[:alnum:]\n' '-' | tr '[:upper:]' '[:lower:]')

            docker buildx bake all --push

  test:
    docker:
      - image: cimg/python:3.11.12
    resource_class: large
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1.1-deps-{{ checksum "Pipfile.lock" }}
      - run:
          name: Install system packages
          command: |
            sudo apt-get update
            sudo apt-get install -y default-jre-headless
      - run:
          name: install dependencies
          command: |
            pip install pipenv
            pipenv install --dev
      - save_cache:
          key: v1.1-deps-{{ checksum "Pipfile.lock" }}
          paths:
            - ~/.local/share/virtualenvs
      - run:
          name: run unit tests
          command: |
            pipenv run coverage run --source=. -m unittest discover -s . -p "test_*.py"
      - run:
          name: Generate coverage report
          command: |
            pipenv run coverage report
            pipenv run coverage xml
            pipenv run coverage html
      - store_artifacts:
          path: htmlcov

  lint-python:
    docker:
      - image: cimg/python:3.11.12
    resource_class: small
    steps:
      - checkout
      - run:
          name: Install black
          command: pip install black==25.1.0
      - run:
          name: Check Python formatting
          command: black . --check

  lint-docstrings:
    docker:
      - image: cimg/python:3.11.12
    resource_class: small
    steps:
      - checkout
      - run:
          name: Install pydoclint
          command: pip install pydoclint==0.6.10
      - run:
          name: Check docstring formatting
          command: pydoclint --style=google --quiet .

  lint-terraform:
    docker:
      - image: docker.mirror.hashicorp.services/hashicorp/terraform:1.13.1
    resource_class: small
    steps:
      - checkout
      - run:
          name: Check terraform formatting
          command: terraform fmt -check -recursive -diff

  terraform-plan:
    parameters:
      aws_account:
        type: enum
        description: The short name of the AWS account, used to reference the relevant `tfbackend` file, and auth credentials
        enum: ["prod", "non_prod"]
      access_key:
        type: env_var_name
      secret_key:
        type: env_var_name
    working_directory: /tmp/project
    docker:
      - image: docker.mirror.hashicorp.services/hashicorp/terraform:1.13.1
    resource_class: small
    steps:
      - checkout
      - run:
          name: terraform plan
          command: |
            # This transformation should match the workspace_prefix set in terraform/pipeline/main.tf locals block
            export SANITISED_CIRCLE_BRANCH=$(echo ${CIRCLE_BRANCH:0:30} | tr -c '[:alnum:]\n' '-' | tr '[:upper:]' '[:lower:]')
            export AWS_ACCESS_KEY_ID=${<< parameters.access_key >>}
            export AWS_SECRET_ACCESS_KEY=${<< parameters.secret_key >>}
            cd terraform/pipeline
            export AWS_ACCOUNT_ID=${AWS_ACCOUNT_ID_<< parameters.aws_account >>}
            terraform init -input=false -backend-config=../<< parameters.aws_account >>.s3.tfbackend
            terraform workspace select ${SANITISED_CIRCLE_BRANCH} || terraform workspace new ${SANITISED_CIRCLE_BRANCH}
            terraform plan -out tfapply
      - store_artifacts:
          path: terraform/pipeline/tfapply
      - persist_to_workspace:
          root: .
          paths:
            - terraform/pipeline/tfapply
            - terraform/pipeline/.*
            - .

  terraform-apply:
    parameters:
      aws_account:
        type: enum
        description: The short name of the AWS account, used to reference the relevant auth credentials
        enum: ["prod", "non_prod"]
      access_key:
        type: env_var_name
      secret_key:
        type: env_var_name
    docker:
      - image: docker.mirror.hashicorp.services/hashicorp/terraform:1.13.1
    resource_class: small
    steps:
      - checkout
      - attach_workspace:
          at: .
      - run:
          name: terraform apply
          command: |
            export AWS_ACCESS_KEY_ID=${<< parameters.access_key >>}
            export AWS_SECRET_ACCESS_KEY=${<< parameters.secret_key >>}
            cd terraform/pipeline
            terraform apply -auto-approve tfapply
      - run:
          name: save pipeline resources bucket name
          command: |
            cd terraform/pipeline
            export AWS_ACCESS_KEY_ID=${<< parameters.access_key >>}
            export AWS_SECRET_ACCESS_KEY=${<< parameters.secret_key >>}
            echo $(terraform output --raw pipeline_resources_bucket_name) > pipeline_resources_bucket_name
      - run:
          name: save datasets bucket name
          command: |
            cd terraform/pipeline
            export AWS_ACCESS_KEY_ID=${<< parameters.access_key >>}
            export AWS_SECRET_ACCESS_KEY=${<< parameters.secret_key >>}
            echo $(terraform output --raw datasets_bucket_name) > datasets_bucket_name
      - persist_to_workspace:
          root: .
          paths:
            - ./terraform/pipeline/pipeline_resources_bucket_name
            - ./terraform/pipeline/datasets_bucket_name

  deploy-dependencies:
    parameters:
      access_key:
        type: env_var_name
      secret_key:
        type: env_var_name
    docker:
      - image: cimg/python:3.11.12
    resource_class: small
    steps:
      - attach_workspace:
          at: .
      - aws-cli/setup:
          region: $AWS_REGION
      - run:
          name: Setup Environment Variables
          command: |
            echo 'export AWS_ACCESS_KEY_ID="${<< parameters.access_key >>}"' >> "$BASH_ENV"
            echo 'export AWS_SECRET_ACCESS_KEY="${<< parameters.secret_key >>}"' >> "$BASH_ENV"
      - run:
          name: package utils, schemas, projects and environment
          command: |
            mkdir dependencies && zip -r dependencies/dependencies.zip utils schemas projects environment polars_utils
      - run:
          name: Download Deequ jar
          command: |
            wget https://repo1.maven.org/maven2/com/amazon/deequ/deequ/2.0.8-spark-3.5/deequ-2.0.8-spark-3.5.jar -O dependencies/deequ-2.0.8-spark-3.5.jar
      - run:
          name: Package PyDeequ
          command: |
            pip install -t ./target pydeequ==1.5.0
            cd target && zip -r pydeequ-1.5.0.zip pydeequ && cd ..
            mv target/pydeequ-1.5.0.zip dependencies/pydeequ-1.5.0.zip
            rm -rf target
      - run:
          name: Sync dependencies to S3
          command: |
            PIPELINE_RESOURCES=$(cat terraform/pipeline/pipeline_resources_bucket_name)
            aws s3 sync dependencies "s3://$PIPELINE_RESOURCES/dependencies"

  copy-main-data:
    docker:
      - image: cimg/base:current
    resource_class: small
    steps:
      - attach_workspace:
          at: .
      - aws-cli/setup:
          region: $AWS_REGION
      - run:
          name: Setup Environment Variables
          command: |
            echo 'export AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID_non_prod}"' >> "$BASH_ENV"
            echo 'export AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY_non_prod}"' >> "$BASH_ENV"
            echo 'export DATASET_BUCKET=$(cat terraform/pipeline/datasets_bucket_name)' >> "$BASH_ENV"
            echo 'export RESOURCES_BUCKET=$(cat terraform/pipeline/pipeline_resources_bucket_name)' >> "$BASH_ENV"
      - run:
          name: Copy main datasets to non-prod dataset bucket
          command: |
            aws s3 sync "s3://sfc-main-datasets/domain=CQC/dataset=delta_locations_api/version=3.1.0/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=CQC/dataset=delta_locations_api/version=3.1.0/"
            aws s3 sync "s3://sfc-main-datasets/domain=CQC/dataset=delta_providers_api/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=CQC/dataset=delta_providers_api/"
            aws s3 sync "s3://sfc-main-datasets/domain=CQC/dataset=cqc_locations_03_full_flattened/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=CQC/dataset=cqc_locations_03_full_flattened/"
            aws s3 sync "s3://sfc-main-datasets/domain=CQC/dataset=cqc_providers_03_full_flattened/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=CQC/dataset=cqc_providers_03_full_flattened/"
            aws s3 sync "s3://sfc-main-datasets/domain=CQC/dataset=cqc_locations_04_full_cleaned_registered/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=CQC/dataset=cqc_locations_04_full_cleaned_registered/"
            aws s3 sync "s3://sfc-main-datasets/domain=CQC/dataset=postcode_corrections/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=CQC/dataset=postcode_corrections/"
            aws s3 sync "s3://sfc-main-datasets/domain=ONS/dataset=postcode_directory_cleaned/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=ONS/dataset=postcode_directory_cleaned/"
            aws s3 sync "s3://sfc-main-datasets/domain=ASCWDS/dataset=workplace/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=ASCWDS/dataset=workplace/"
            aws s3 sync "s3://sfc-main-datasets/domain=ASCWDS/dataset=workplace_cleaned/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=ASCWDS/dataset=workplace_cleaned/"
            aws s3 sync "s3://sfc-main-datasets/domain=ASCWDS/dataset=worker/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=ASCWDS/dataset=worker/"
            aws s3 sync "s3://sfc-main-datasets/domain=ASCWDS/dataset=worker_cleaned/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=ASCWDS/dataset=worker_cleaned/"
            aws s3 sync "s3://sfc-main-datasets/domain=capacity_tracker/dataset=capacity_tracker_care_home_cleaned/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=capacity_tracker/dataset=capacity_tracker_care_home_cleaned/"
            aws s3 sync "s3://sfc-main-datasets/domain=capacity_tracker/dataset=capacity_tracker_non_residential_cleaned/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=capacity_tracker/dataset=capacity_tracker_non_residential_cleaned/"
            aws s3 sync "s3://sfc-main-datasets/domain=CQC/dataset=pir_cleaned/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=CQC/dataset=pir_cleaned/"
            aws s3 sync "s3://sfc-main-datasets/domain=ind_cqc_filled_posts/dataset=ind_cqc_06_estimated_filled_posts/" "s3://$(cat terraform/pipeline/datasets_bucket_name)/domain=ind_cqc_filled_posts/dataset=main_ind_cqc_06_estimated_filled_posts/"
      - run:
          name: Copy models to non-prod dataset
          command: |
            aws s3 sync "s3://sfc-main-pipeline-resources/models/" "s3://$(cat terraform/pipeline/pipeline_resources_bucket_name)/models/"

  terraform-destroy:
    working_directory: /tmp/project
    docker:
      - image: cimg/python:3.11.12
    resource_class: small
    steps:
      - checkout
      - run:
          name: Setup Environment
          command: |
            echo 'export AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID_non_prod}"' >> $BASH_ENV
            echo 'export AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY_non_prod}"' >> $BASH_ENV
            echo 'export CIRCLE_BRANCH="<< pipeline.parameters.GHA_Meta >>"' >> $BASH_ENV
            echo 'export SANITISED_CIRCLE_BRANCH=$(echo ${CIRCLE_BRANCH:0:30} | tr -c "[:alnum:]\n" "-" | tr "[:upper:]" "[:lower:]")' >> $BASH_ENV
      - run:
          name: terraform destroy
          command: |
            # --- Safeguard to never destroy main ---
            if [ "$SANITISED_CIRCLE_BRANCH" = "main" ]; then
              echo "Skipping destroy for main branch"
              exit 0
            fi
            # --- Select workspace ---
            cd terraform/pipeline
            terraform init -input=false -backend-config=../non_prod.s3.tfbackend
            terraform workspace select ${SANITISED_CIRCLE_BRANCH}
            # --- Force-empty dataset bucket for this branch ---
            BUCKET_NAME=$(cat datasets_bucket_name)
            echo "Emptying dataset bucket: $BUCKET_NAME"
            aws s3 rm "s3://${BUCKET_NAME}" --recursive || true
            # --- Run destroy ---
            terraform destroy -auto-approve
      - run:
          name: delete workspace
          command: |
            cd terraform/pipeline
            terraform workspace select default
            terraform workspace delete ${SANITISED_CIRCLE_BRANCH}


workflows:
  test-plan-approve-and-deploy-to-main:
    unless: << pipeline.parameters.GHA_Action >>
    jobs:
      - task-containerisation:
          access_key: AWS_ACCESS_KEY_ID
          secret_key: AWS_SECRET_ACCESS_KEY
          aws_account_id: AWS_ACCOUNT_ID
          filters:
            branches:
              only: main
      - test:
          filters:
            branches:
              only: main
      - terraform-plan:
          access_key: AWS_ACCESS_KEY_ID
          secret_key: AWS_SECRET_ACCESS_KEY
          aws_account: "prod"
          requires:
            - test
            - task-containerisation
      - plan-approval:
          type: approval
          requires:
            - terraform-plan
      - terraform-apply:
          access_key: AWS_ACCESS_KEY_ID
          secret_key: AWS_SECRET_ACCESS_KEY
          aws_account: "prod"
          requires:
            - plan-approval
      - deploy-dependencies:
          access_key: AWS_ACCESS_KEY_ID
          secret_key: AWS_SECRET_ACCESS_KEY
          requires:
            - terraform-apply


  test-plan-and-deploy-to-dev:
    unless: << pipeline.parameters.GHA_Action >>
    jobs:
      - task-containerisation:
          access_key: AWS_ACCESS_KEY_ID_non_prod
          secret_key: AWS_SECRET_ACCESS_KEY_non_prod
          aws_account_id: AWS_ACCOUNT_ID_non_prod
          filters:
            branches:
              ignore: main
      - lint-python:
          filters:
            branches:
              ignore: main
      - lint-terraform:
          filters:
            branches:
              ignore: main
      - lint-docstrings:
          filters:
            branches:
              ignore: main
      - terraform-plan:
          access_key: AWS_ACCESS_KEY_ID_non_prod
          secret_key: AWS_SECRET_ACCESS_KEY_non_prod
          aws_account: "non_prod"
          requires:
            - lint-terraform
            - task-containerisation
      - terraform-apply:
          access_key: AWS_ACCESS_KEY_ID_non_prod
          secret_key: AWS_SECRET_ACCESS_KEY_non_prod
          aws_account: "non_prod"
          requires:
            - terraform-plan
      - deploy-dependencies:
          access_key: AWS_ACCESS_KEY_ID_non_prod
          secret_key: AWS_SECRET_ACCESS_KEY_non_prod
          requires:
            - terraform-apply
      - copy-main-data:
          requires:
            - terraform-apply
      - test:
          requires:
            - terraform-apply
          filters:
            branches:
              ignore: main

  delete-development-environment:
    when: << pipeline.parameters.GHA_Action >>
    jobs:
      - terraform-destroy
