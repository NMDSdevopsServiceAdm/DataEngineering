version: 2.1

parameters:
  GHA_Actor:
    type: string
    default: ""
  GHA_Action:
    type: string
    default: ""
  GHA_Event:
    type: string
    default: ""
  GHA_Meta:
    type: string
    default: ""

orbs:
  aws-s3: circleci/aws-s3@3.0
  aws-cli: circleci/aws-cli@5.4.1

jobs:
  task-containerisation:
    docker:
      - image: docker:latest
    steps:
      - checkout
      - setup_remote_docker:
          docker_layer_caching: true
      - aws-cli/setup:
          region: "eu-west-2"
      - run:
          name: Build Docker Images
          command: |
            # Authenticate Docker to ECR
            docker login -u AWS -p $(aws ecr get-login-password --region eu-west-2) ${AWS_ACCOUNT_ID}.dkr.ecr.eu-west-2.amazonaws.com
            
            echo "Rebuilding create dataset snapshot container and pushing to ECR."
            docker buildx build  --platform linux/amd64 -t latest --no-cache --pull -f lambdas/create_dataset_snapshot/Dockerfile .
            
            # Push the image
            docker tag latest ${AWS_ACCOUNT_ID}.dkr.ecr.eu-west-2.amazonaws.com/lambda/create-snapshot:${CIRCLE_BRANCH}
            docker push ${AWS_ACCOUNT_ID}.dkr.ecr.eu-west-2.amazonaws.com/lambda/create-snapshot:${CIRCLE_BRANCH}
          
            echo "Rebuilding check dataset equality container and pushing to ECR."
            docker buildx build  --platform linux/amd64 -t latest --no-cache --pull -f lambdas/check_dataset_equality/Dockerfile .

            # Push the image
            docker tag latest ${AWS_ACCOUNT_ID}.dkr.ecr.eu-west-2.amazonaws.com/lambda/check-datasets-equal:${CIRCLE_BRANCH}
            docker push ${AWS_ACCOUNT_ID}.dkr.ecr.eu-west-2.amazonaws.com/lambda/check-datasets-equal:${CIRCLE_BRANCH}
            
            echo "Building the CQC Providers job and push to ECR."
            docker buildx build  --platform linux/amd64 -t latest --no-cache --pull -f projects/_01_ingest/cqc_api/fargate/providers/Dockerfile .

            # Push the image
            docker tag latest ${AWS_ACCOUNT_ID}.dkr.ecr.eu-west-2.amazonaws.com/ingest/cqc/providers:${CIRCLE_BRANCH}
            docker push ${AWS_ACCOUNT_ID}.dkr.ecr.eu-west-2.amazonaws.com/ingest/cqc/providers:${CIRCLE_BRANCH}

  test:
    docker:
      - image: circleci/python:3.9.6
    resource_class: small

    steps:
      - checkout

      - restore_cache:
          keys:
            - v1.1-deps-{{ checksum "Pipfile.lock" }}

      - run:
          name: Install system packages
          command: |
            sudo apt-get update
            sudo apt-get install -y default-jre-headless

      - run:
          name: install dependencies
          command: |
            sudo pip install pipenv
            pipenv install --dev

      - save_cache:
          key: v1.1-deps-{{ checksum "Pipfile.lock" }}
          paths:
            - ~/.local/share/virtualenvs

      - run:
          name: run unit tests
          command: |
            pipenv run python -m unittest discover -s . -p "test_*.py"

      - run:
          name: run integration tests
          command: |
            pipenv run python -m unittest discover tests/integration



  lint-python:
    docker:
      - image: circleci/python:3.9.6
    resource_class: small
    steps:
      - checkout
      - run:
          name: Install black
          command: pip install black==23.7.0
      - run:
          name: Check Python formatting
          command: black . --check

  lint-docstrings:
    docker:
      - image: circleci/python:3.9.6
    resource_class: small
    steps:
      - checkout
      - run:
          name: Install pydoclint
          command: pip install pydoclint==0.5.9
      - run:
          name: Check docstring formatting
          command: pydoclint --style=google --quiet .

  lint-terraform:
    docker:
      - image: docker.mirror.hashicorp.services/hashicorp/terraform:1.2.1
    resource_class: small
    steps:
      - checkout
      - run:
          name: Check terraform formatting
          command: terraform fmt -check -recursive -diff

  terraform-plan:
    working_directory: /tmp/project
    docker:
      - image: docker.mirror.hashicorp.services/hashicorp/terraform:1.2.1
    resource_class: small
    steps:
      - checkout
      - run:
          name: terraform plan
          command: |
            cd terraform/pipeline
            terraform init -input=false
            terraform workspace select ${CIRCLE_BRANCH} || terraform workspace new ${CIRCLE_BRANCH}
            terraform plan -out tfapply
      - store_artifacts:
          path: terraform/pipeline/tfapply
      - persist_to_workspace:
          root: .
          paths:
            - terraform/pipeline/tfapply
            - terraform/pipeline/.*
            - .

  terraform-apply:
    docker:
      - image: docker.mirror.hashicorp.services/hashicorp/terraform:1.2.1
    resource_class: small
    steps:
      - checkout
      - attach_workspace:
          at: .

      - run:
          name: terraform apply
          command: |
            cd terraform/pipeline
            terraform apply -auto-approve tfapply

      - run:
          name: save pipeline resources bucket name
          command: |
            cd terraform/pipeline
            echo $(terraform output --raw pipeline_resources_bucket_name) > pipeline_resources_bucket_name

      - run:
          name: save datasets bucket name
          command: |
            cd terraform/pipeline
            echo $(terraform output --raw datasets_bucket_name) > datasets_bucket_name

      - persist_to_workspace:
          root: .
          paths:
            - ./terraform/pipeline/pipeline_resources_bucket_name
            - ./terraform/pipeline/datasets_bucket_name

  deploy-dependencies:
    docker:
      - image: circleci/python:3.9.6
    resource_class: small
    steps:
      - attach_workspace:
          at: .

      - run:
          name: package utils, schemas, projects and environment
          command: |
            mkdir dependencies && zip -r dependencies/dependencies.zip utils schemas projects environment

      - run:
          name: Download Deequ jar
          command: |
            wget https://repo1.maven.org/maven2/com/amazon/deequ/deequ/2.0.7-spark-3.3/deequ-2.0.7-spark-3.3.jar -O dependencies/deequ-2.0.7-spark-3.3.jar

      - run:
          name: Package PyDeequ
          command: |
            pip install -t ./target pydeequ==1.4.0
            cd target && zip -r pydeequ-1.4.0.zip pydeequ && cd ..
            mv target/pydeequ-1.4.0.zip dependencies/pydeequ-1.4.0.zip
            rm -rf target

      - aws-s3/sync:
          aws-region: AWS_REGION
          from: dependencies
          to: "s3://$(cat terraform/pipeline/pipeline_resources_bucket_name)/dependencies"

  copy-default-data:
    docker:
      - image: cimg/base:current
    resource_class: small
    steps:
      - attach_workspace:
          at: .

      - aws-s3/sync:
          aws-region: AWS_REGION
          from: "s3://sfc-default-datasets/"
          to: "s3://$(cat terraform/pipeline/datasets_bucket_name)/"

      - aws-s3/sync:
          aws-region: AWS_REGION
          from: "s3://sfc-main-pipeline-resources/models/"
          to: "s3://$(cat terraform/pipeline/pipeline_resources_bucket_name)/models/"

  terraform-destroy:
    working_directory: /tmp/project
    docker:
      - image: docker.mirror.hashicorp.services/hashicorp/terraform:1.2.1
    resource_class: small
    steps:
      - checkout
      - run:
          name: terraform destroy
          command: |
            cd terraform/pipeline
            terraform init -input=false
            terraform workspace select << pipeline.parameters.GHA_Meta >>
            terraform destroy -auto-approve
      - run:
          name: delete workspace
          command: |
            cd terraform/pipeline
            terraform workspace select default
            terraform workspace delete << pipeline.parameters.GHA_Meta >>


workflows:
  version: 2

  test-plan-approve-and-deploy-to-main:
    unless: << pipeline.parameters.GHA_Action >>
    jobs:
      - lambda-function-containerisation:
          filters:
            branches:
              only: main
      - test:
          filters:
            branches:
              only: main
      - terraform-plan:
          requires:
            - test
            - lambda-function-containerisation
      - plan-approval:
          type: approval
          requires:
            - terraform-plan
      - terraform-apply:
          requires:
            - plan-approval
      - deploy-dependencies:
          requires:
            - terraform-apply


  test-plan-and-deploy-to-dev:
    unless: << pipeline.parameters.GHA_Action >>
    jobs:
      - lambda-function-containerisation:
          filters:
            branches:
              ignore: main
      - test:
          filters:
            branches:
              ignore: main
      - lint-python:
          filters:
            branches:
              ignore: main
      - lint-terraform:
          filters:
            branches:
              ignore: main
      - lint-docstrings:
          filters:
            branches:
              ignore: main
      - terraform-plan:
          requires:
            - lint-terraform
            - test
            - lambda-function-containerisation
      - terraform-apply:
          requires:
            - terraform-plan
      - deploy-dependencies:
          requires:
            - terraform-apply
      - copy-default-data:
          requires:
            - terraform-apply

  delete-development-environment:
    when: << pipeline.parameters.GHA_Action >>
    jobs:
      - terraform-destroy
