from utils import utils


def generate_ethnicity_parquet(output_destination):
    spark = utils.get_spark()
    columns = ["locationid", "mainjrid", "ethnicity", "import_date"]

    rows = [
        ("1-000000001", 1, 31, "20200101"),
        ("1-000000001", 1, 32, "20200101"),
        ("1-000000001", 1, 42, "20200101"),
        ("1-000000001", 2, 46, "20200101"),
        ("1-000000001", 3, 98, "20200101"),
        ("1-000000001", 3, 99, "20200101"),
        ("1-000000001", 3, -1, "20200101"),
        ("1-000000002", 1, 35, "20200101"),
        ("1-000000002", 3, 36, "20200101"),
        ("1-000000002", 2, 37, "20200101"),
        ("1-000000003", 1, 31, "20200101"),
        ("1-000000003", 2, 35, "20200101"),
        ("1-000000003", 3, 39, "20200101"),
        ("1-000000004", 1, 47, "20200101"),
        ("1-000000004", 2, 98, "20200101"),
        ("1-000000004", 3, 44, "20200101"),
        ("1-000000001", 1, 38, "20190101"),
        ("1-000000001", 1, 38, "20210101"),
    ]

    df = spark.createDataFrame(rows, columns)

    if output_destination:
        df.coalesce(1).write.mode("overwrite").parquet(output_destination)

    return df
